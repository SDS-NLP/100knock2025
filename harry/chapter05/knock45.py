import requests
import os
from dotenv import load_dotenv

# APIã‚­ãƒ¼ã®èª­ã¿è¾¼ã¿
load_dotenv()
API_KEY = os.getenv("GROQ_API_KEY")
API_URL = "https://api.groq.com/openai/v1/chat/completions"
MODEL = "meta-llama/llama-4-scout-17b-16e-instruct"

headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {API_KEY}"
}

# Step1ã®è³ªå•
q1 = """ã¤ã°ã‚ã¡ã‚ƒã‚“ã¯æ¸‹è°·é§…ã‹ã‚‰æ±æ€¥æ±æ¨ªç·šã«ä¹—ã‚Šã€è‡ªç”±ãŒä¸˜é§…ã§ä¹—ã‚Šæ›ãˆã¾ã—ãŸã€‚
æ±æ€¥å¤§äº•ç”ºç·šã®å¤§äº•ç”ºæ–¹é¢ã®é›»è»Šã«ä¹—ã‚Šæ›ãˆãŸã¨ãã€å„é§…åœè»Šã«ä¹—è»Šã™ã¹ãã¨ã“ã‚ã€
é–“é•ãˆã¦æ€¥è¡Œã«ä¹—è»Šã—ã¦ã—ã¾ã£ãŸã“ã¨ã«æ°—ä»˜ãã¾ã—ãŸã€‚
è‡ªç”±ãŒä¸˜ã®æ¬¡ã®æ€¥è¡Œåœè»Šé§…ã§é™è»Šã—ã€åå¯¾æ–¹å‘ã®é›»è»Šã§ä¸€é§…æˆ»ã£ãŸé§…ãŒã¤ã°ã‚ã¡ã‚ƒã‚“ã®ç›®çš„åœ°ã§ã—ãŸã€‚
ç›®çš„åœ°ã®é§…ã®åå‰ã‚’ç­”ãˆã¦ãã ã•ã„ã€‚"""

# Step2ã®è³ªå•
q2 = """ã•ã‚‰ã«ã€ã¤ã°ã‚ã¡ã‚ƒã‚“ãŒè‡ªç”±ãŒä¸˜é§…ã§ä¹—ã‚Šæ›ãˆãŸã¨ãã€
å…ˆã»ã©ã¨ã¯åå¯¾æ–¹å‘ã®æ€¥è¡Œé›»è»Šã«é–“é•ã£ã¦ä¹—è»Šã—ã¦ã—ã¾ã£ãŸå ´åˆã‚’è€ƒãˆã¾ã™ã€‚
ç›®çš„åœ°ã®é§…ã«å‘ã‹ã†ãŸã‚ã€è‡ªç”±ãŒä¸˜ã®æ¬¡ã®æ€¥è¡Œåœè»Šé§…ã§é™è»Šã—ãŸå¾Œã€
åå¯¾æ–¹å‘ã®å„é§…åœè»Šã«ä¹—è»Šã—ãŸå ´åˆã€ä½•é§…å…ˆã®é§…ã§é™ã‚Šã‚Œã°è‰¯ã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ"""

# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™
log_path = "dialogue_log.txt"
with open(log_path, "w", encoding="utf-8") as log_file:
    log_file.write("=== ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¯¾è©±ãƒ­ã‚° ===\n\n")
    log_file.write("ğŸ§‘ Step 1:\n" + q1 + "\n")

# Step1: åˆå›ã®è³ªå•
payload1 = {
    "model": MODEL,
    "temperature": 0,
    "messages": [
        {"role": "system", "content": "ã‚ãªãŸã¯é‰„é“ã«è©³ã—ã„æ—¥æœ¬ã®æ¡ˆå†…ä¿‚ã§ã™ã€‚é§…ã®é †ç•ªã‚„é›»è»Šã®ç¨®é¡ã«ç²¾é€šã—ã€ä¸å¯§ã«æ¨è«–ã—ã¦ç­”ãˆã¦ãã ã•ã„ã€‚"},
        {"role": "user", "content": q1}
    ]
}

response1 = requests.post(API_URL, headers=headers, json=payload1)

if response1.status_code == 200:
    answer1 = response1.json()["choices"][0]["message"]["content"].strip()
    print("ğŸ§  Step 1 ã®å¿œç­”:")
    print(answer1)
    with open(log_path, "a", encoding="utf-8") as log_file:
        log_file.write("\nğŸ¤– Step 1 å¿œç­”:\n" + answer1 + "\n")
else:
    print("âŒ Step 1 APIã‚¨ãƒ©ãƒ¼:", response1.status_code, response1.text)
    exit()

# Step2: ãã®å¿œç­”ã‚’è¸ã¾ãˆãŸæ¬¡ã®è³ªå•
payload2 = {
    "model": MODEL,
    "temperature": 0,
    "messages": [
        {"role": "system", "content": "ã‚ãªãŸã¯é‰„é“ã«è©³ã—ã„æ—¥æœ¬ã®æ¡ˆå†…ä¿‚ã§ã™ã€‚é§…ã®é †ç•ªã‚„é›»è»Šã®ç¨®é¡ã«ç²¾é€šã—ã€ä¸å¯§ã«æ¨è«–ã—ã¦ç­”ãˆã¦ãã ã•ã„ã€‚"},
        {"role": "user", "content": q1},
        {"role": "assistant", "content": answer1},
        {"role": "user", "content": q2}
    ]
}

with open(log_path, "a", encoding="utf-8") as log_file:
    log_file.write("\nğŸ§‘ Step 2:\n" + q2 + "\n")

response2 = requests.post(API_URL, headers=headers, json=payload2)

if response2.status_code == 200:
    answer2 = response2.json()["choices"][0]["message"]["content"].strip()
    print("\nğŸ§  Step 2 ã®å¿œç­”:")
    print(answer2)
    with open(log_path, "a", encoding="utf-8") as log_file:
        log_file.write("\nğŸ¤– Step 2 å¿œç­”:\n" + answer2 + "\n")
else:
    print("âŒ Step 2 APIã‚¨ãƒ©ãƒ¼:", response2.status_code, response2.text)