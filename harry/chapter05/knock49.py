import requests
import os
from dotenv import load_dotenv

# .env ã‹ã‚‰ API ã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿
load_dotenv()
API_KEY = os.getenv("GROQ_API_KEY")
API_URL = "https://api.groq.com/openai/v1/chat/completions"
MODEL = "meta-llama/llama-4-scout-17b-16e-instruct"

HEADERS = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {API_KEY}"
}

# neko.txt ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€
file_path = "neko.txt"
if not os.path.isfile(file_path):
    print("âŒ neko.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    exit()

with open(file_path, "r", encoding="utf-8") as f:
    text = f.read().strip()

# API ã¸ã®å•ã„åˆã‚ã›
payload = {
    "model": MODEL,
    "temperature": 0,
    "messages": [
        {"role": "user", "content": text}
    ]
}

response = requests.post(API_URL, headers=HEADERS, json=payload)

# ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¡¨ç¤º
if response.status_code == 200:
    response_data = response.json()

    # å‡ºåŠ›å†…å®¹ï¼ˆãƒ¢ãƒ‡ãƒ«ã®å¿œç­”ï¼‰
    output = response_data["choices"][0]["message"]["content"].strip()
    print("\nğŸ§  ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›:")
    print(output)

    # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®è¡¨ç¤º
    usage = response_data["usage"]
    print("\nğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³æ•°æƒ…å ±:")
    print(f"ãƒ»å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆprompt_tokensï¼‰: {usage.get('prompt_tokens', 'N/A')}")
    print(f"ãƒ»å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆcompletion_tokensï¼‰: {usage.get('completion_tokens', 'N/A')}")
    print(f"ãƒ»åˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆtotal_tokensï¼‰: {usage.get('total_tokens', 'N/A')}")
else:
    print("âŒ APIã‚¨ãƒ©ãƒ¼:")
    print(response.status_code)
    print(response.text)