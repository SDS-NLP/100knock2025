import requests
import os
from dotenv import load_dotenv

# APIã‚­ãƒ¼èª­ã¿è¾¼ã¿
load_dotenv()
API_KEY = os.getenv("GROQ_API_KEY")
API_URL = "https://api.groq.com/openai/v1/chat/completions"
MODEL = "meta-llama/llama-4-scout-17b-16e-instruct"

headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {API_KEY}"
}

# ãŠé¡Œã®å…¥åŠ›ï¼ˆå¿…è¦ã«å¿œã˜ã¦å›ºå®šã§ã‚‚OKï¼‰
theme = input("ğŸ¯ å·æŸ³ã®ãŠé¡Œã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æº–å‚™
prompt = f"""
ä»¥ä¸‹ã®ãŠé¡Œã€Œ{theme}ã€ã«é–¢ã™ã‚‹å·æŸ³ã‚’10å€‹ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒ»å·æŸ³ã¯5-7-5ã®å½¢å¼ã§ã€æ—¥æœ¬èªã§ãƒ¦ãƒ¼ãƒ¢ã‚¢ã‚„é¢¨åˆºã‚’äº¤ãˆã¦ãã ã•ã„ã€‚
ãƒ»ç•ªå·ä»˜ãã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: 1. ã€‡ã€‡ã€‡ï¼‰
"""

payload = {
    "model": MODEL,
    "temperature": 0.7,
    "messages": [
        {"role": "system", "content": "ã‚ãªãŸã¯æ—¥æœ¬èªã®å·æŸ³ã‚’å‰µä½œã™ã‚‹é”äººã§ã™ã€‚ãƒªã‚ºãƒ ã¨ãƒ¦ãƒ¼ãƒ¢ã‚¢ã‚’å¤§åˆ‡ã«ã—ã¦ãã ã•ã„ã€‚"},
        {"role": "user", "content": prompt}
    ]
}

response = requests.post(API_URL, headers=headers, json=payload)

if response.status_code == 200:
    content = response.json()["choices"][0]["message"]["content"].strip()
    print("\nğŸ´ å·æŸ³ã®æ¡ˆï¼ˆ10å€‹ï¼‰:")
    print(content)

    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    with open("senryu_log.txt", "w", encoding="utf-8") as f:
        f.write(f"ãŠé¡Œ: {theme}\n\n")
        f.write(content)
        print("\nâœ… senryu_log.txt ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
else:
    print("âŒ APIã‚¨ãƒ©ãƒ¼:", response.status_code, response.text)
